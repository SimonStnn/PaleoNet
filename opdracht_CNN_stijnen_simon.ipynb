{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a60e89c",
   "metadata": {},
   "source": [
    "AI Deep Learning – Simon Stijnen – May 2025\n",
    "\n",
    "---\n",
    "\n",
    "# Dinosaur Species Classification using Convolutional Neural Networks\n",
    "\n",
    "This notebook implements a CNN model to classify dinosaur species using image data from Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe02ed7",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "\n",
    "In this project, we aim to build a deep learning model capable of distinguishing between 15 different dinosaur species using the [Dinosaur Image Dataset from Kaggle](https://www.kaggle.com/datasets/larserikrisholm/dinosaur-image-dataset-15-species).\n",
    "\n",
    "The main objectives include:\n",
    "\n",
    "1. Splitting the dataset into appropriate training, validation, and test sets\n",
    "2. Selecting an appropriate CNN architecture\n",
    "3. Tuning hyperparameters for optimal performance\n",
    "4. Preventing overfitting with proper regularization techniques\n",
    "5. Using Keras' Functional API to build the model\n",
    "6. Evaluating the model with accuracy metrics and confusion matrices\n",
    "7. Achieving an accuracy greater than 70%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457cd0e8",
   "metadata": {},
   "source": [
    "## Dataset Preparation and Splitting\n",
    "\n",
    "We'll use the `split-folders` library to properly split our dataset into training, validation, and test sets with a 70%-15%-15% ratio. This ensures we have proper separation for model evaluation and prevents data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb63c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input, applications\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a79dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kagglehub\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"larserikrisholm/dinosaur-image-dataset-15-species\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451cdaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install split-folders\n",
    "\n",
    "import splitfolders\n",
    "\n",
    "# Dataset pad (pas dit aan indien nodig)\n",
    "input_folder = os.path.join(path, \"dinosaur_dataset\")  # Pad naar de dataset\n",
    "# Create absolute path for output directory\n",
    "output_split_dir = os.path.abspath(os.path.join(\"data\", \"dinosaur_dataset_split\"))  # Pad naar de output directory\n",
    "os.makedirs(output_split_dir, exist_ok=True)\n",
    "\n",
    "print(\"output_split_dir:\", output_split_dir)\n",
    "\n",
    "# Split dataset in train (70%), val (15%), test (15%)\n",
    "splitfolders.ratio(\n",
    "    input_folder,\n",
    "    output=output_split_dir,\n",
    "    seed=42,\n",
    "    ratio=(0.7, 0.15, 0.15),\n",
    "    group_prefix=None,\n",
    "    move=False,\n",
    ")\n",
    "\n",
    "print(\"Dataset successfully split into train, validation, and test sets!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae0e3f6",
   "metadata": {},
   "source": [
    "Define the path to the dataset and set the image size and batch size for training, validation, and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b357dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and model parameters\n",
    "img_height, img_width = 192, 192\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c050cea",
   "metadata": {},
   "source": [
    "Define the training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f666f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing and augmentation for training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    preprocessing_function=applications.mobilenet_v2.preprocess_input\n",
    ")\n",
    "\n",
    "# Only preprocessing for validation and test data (no augmentation)\n",
    "val_test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=applications.mobilenet_v2.preprocess_input\n",
    ")\n",
    "\n",
    "# Load data from the split directories\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    f'{output_split_dir}/train',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_data = val_test_datagen.flow_from_directory(\n",
    "    f'{output_split_dir}/val',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_data = val_test_datagen.flow_from_directory(\n",
    "    f'{output_split_dir}/test',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,  # Don't shuffle for consistent evaluation\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "print(f\"Number of training samples: {train_data.samples}\")\n",
    "print(f\"Number of validation samples: {val_data.samples}\")\n",
    "print(f\"Number of test samples: {test_data.samples}\")\n",
    "print(f\"Number of classes: {len(train_data.class_indices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05951643",
   "metadata": {},
   "source": [
    "## Transfer Learning with MobileNetV2\n",
    "\n",
    "Instead of building a CNN from scratch, we'll use transfer learning with MobileNetV2 as our base model. This model has been pre-trained on ImageNet, which means it has already learned to extract useful features from images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b6c1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base model from MobileNetV2 - a lightweight, powerful CNN architecture\n",
    "base_model = applications.MobileNetV2(\n",
    "    input_shape=(img_height, img_width, 3),\n",
    "    include_top=False,  # Exclude the classification layer\n",
    "    weights='imagenet'  # Use pre-trained weights from ImageNet\n",
    ")\n",
    "\n",
    "# Freeze the base model to prevent its weights from being updated during initial training\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create our model by adding custom layers on top of the base model\n",
    "inputs = Input(shape=(img_height, img_width, 3))\n",
    "x = base_model(inputs, training=False)  # Pass the inputs through the base model\n",
    "x = layers.GlobalAveragePooling2D()(x)  # Global average pooling reduces params & prevents overfitting\n",
    "x = layers.Dense(256, activation='relu')(x)  # Add a fully connected layer\n",
    "x = layers.Dropout(0.5)(x)  # Add dropout for regularization\n",
    "outputs = layers.Dense(15, activation='softmax')(x)  # 15 classes output layer\n",
    "\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0651ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First phase: train just the top layers with the base model frozen\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=10,\n",
    "    validation_data=val_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c9b824",
   "metadata": {},
   "source": [
    "## Fine-tuning the model\n",
    "\n",
    "After initial training with the base model frozen, we can unfreeze some of the deeper layers of the base model and train them along with our custom top layers. This allows the model to fine-tune the pre-trained features to our specific dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fc3884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the last few layers of the base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# Freeze all the layers except the last 4 layers\n",
    "for layer in base_model.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile the model with a lower learning rate for fine-tuning\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),  # Use a lower learning rate\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Print which layers are trainable\n",
    "for layer in model.layers:\n",
    "    print(f\"{layer.name}: {layer.trainable}\")\n",
    "    \n",
    "# For the base model, print detailed trainable status\n",
    "if hasattr(layer, 'layers'):  # Check if the layer has sub-layers\n",
    "    for sublayer in layer.layers[-5:]:  # Show the last 5 layers\n",
    "        print(f\"  {sublayer.name}: {sublayer.trainable=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebac264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second phase: fine-tuning with unfrozen layers\n",
    "fine_tune_history = model.fit(\n",
    "    train_data,\n",
    "    epochs=5,\n",
    "    validation_data=val_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb8eda9",
   "metadata": {},
   "source": [
    "## Visualizing Training History\n",
    "\n",
    "Let's plot the training and validation accuracy/loss to see how our model performed during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d990ab15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine histories from both training phases\n",
    "acc = history.history['accuracy'] + fine_tune_history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy'] + fine_tune_history.history['val_accuracy']\n",
    "loss = history.history['loss'] + fine_tune_history.history['loss']\n",
    "val_loss = history.history['val_loss'] + fine_tune_history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot training & validation accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.plot([9, 9], [0, 1], 'r--', label='Start Fine Tuning')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.plot([9, 9], [0, 1], 'r--', label='Start Fine Tuning')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim([0, 1.0])\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2187195b",
   "metadata": {},
   "source": [
    "## Model Evaluation on Test Set\n",
    "\n",
    "Now we'll evaluate our model on the completely separate test set to get a true measure of its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423e8185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbf298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "test_data.reset()  # Reset before predictions\n",
    "y_pred_probs = model.predict(test_data)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Extract the true labels\n",
    "# Since the test generator doesn't shuffle, labels align with class indices\n",
    "y_true = test_data.classes\n",
    "class_labels = list(test_data.class_indices.keys())\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot raw counts confusion matrix\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_labels, yticklabels=class_labels, cmap='Blues')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Confusion Matrix (Counts)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_true, y_pred, target_names=class_labels, digits=3)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Calculate overall metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Macro Precision: {precision_score(y_true, y_pred, average='macro'):.4f}\")\n",
    "print(f\"Macro Recall: {recall_score(y_true, y_pred, average='macro'):.4f}\")\n",
    "print(f\"Macro F1-Score: {f1_score(y_true, y_pred, average='macro'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4b0f7a",
   "metadata": {},
   "source": [
    "## Sample Predictions\n",
    "\n",
    "Let's visualize some sample predictions to see how our model performs on individual images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cc84c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def predict_and_display_image(img_path, model, class_labels):\n",
    "    # Load and preprocess the image\n",
    "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_batch = np.expand_dims(img_array, axis=0)\n",
    "    preprocessed_img = applications.mobilenet_v2.preprocess_input(img_batch)\n",
    "    \n",
    "    # Make prediction\n",
    "    predictions = model.predict(preprocessed_img)\n",
    "    predicted_class = np.argmax(predictions[0])\n",
    "    confidence = predictions[0][predicted_class]\n",
    "    \n",
    "    # Display image and prediction\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Predicted: {class_labels[predicted_class]}\\nConfidence: {confidence:.2f}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Show top 3 predictions\n",
    "    top_3_idx = np.argsort(predictions[0])[-3:][::-1]\n",
    "    top_3_classes = [class_labels[i] for i in top_3_idx]\n",
    "    top_3_confidences = [predictions[0][i] for i in top_3_idx]\n",
    "    \n",
    "    for cls, conf in zip(top_3_classes, top_3_confidences):\n",
    "        print(f\"{cls}: {conf:.4f}\")\n",
    "\n",
    "# Get a list of dinosaur classes\n",
    "dino_classes = list(train_data.class_indices.keys())\n",
    "\n",
    "# Define the test directory path\n",
    "test_dir = os.path.join(output_split_dir, 'test')\n",
    "\n",
    "# Sample a few images from different classes for prediction\n",
    "for dino_class in random.sample(dino_classes, 3):\n",
    "    class_dir = os.path.join(test_dir, dino_class)\n",
    "    image_files = os.listdir(class_dir)\n",
    "    sample_image = os.path.join(class_dir, random.choice(image_files))\n",
    "    print(f\"\\nSample from class: {dino_class}\")\n",
    "    predict_and_display_image(sample_image, model, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3fd7b0",
   "metadata": {},
   "source": [
    "## Analyze Misclassifications\n",
    "\n",
    "Let's examine some of the misclassified images to understand what might be confusing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77440ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file paths and true labels from the test directory\n",
    "test_image_paths = []\n",
    "test_labels = []\n",
    "\n",
    "for class_idx, class_name in enumerate(test_data.class_indices):\n",
    "    class_dir = os.path.join(test_dir, class_name)\n",
    "    for img_name in os.listdir(class_dir):\n",
    "        if img_name.endswith('.jpg'):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            test_image_paths.append(img_path)\n",
    "            test_labels.append(class_idx)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "test_image_paths = np.array(test_image_paths)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# Find misclassified indices\n",
    "misclassified_indices = np.where(y_pred != y_true)[0]\n",
    "\n",
    "# Display random misclassified images\n",
    "n_display = min(6, len(misclassified_indices))\n",
    "sample_indices = np.random.choice(misclassified_indices, n_display, replace=False)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    # Get the file path for this test image\n",
    "    img_idx = idx % len(test_image_paths)  # Handle case where idx is out of range\n",
    "    img_path = test_image_paths[img_idx]\n",
    "    \n",
    "    # Load and preprocess the image\n",
    "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_batch = np.expand_dims(img_array, axis=0)\n",
    "    preprocessed_img = applications.mobilenet_v2.preprocess_input(img_batch)\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = model.predict(preprocessed_img)\n",
    "    predicted_class = np.argmax(predictions[0])\n",
    "    confidence = predictions[0][predicted_class]\n",
    "    \n",
    "    # Get true class\n",
    "    true_class = y_true[idx]\n",
    "    \n",
    "    # Plot\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"True: {class_labels[true_class]}\\nPred: {class_labels[predicted_class]}\\nConf: {confidence:.2f}\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecc9115",
   "metadata": {},
   "source": [
    "## Save the Model\n",
    "\n",
    "Let's save our trained model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00818204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model architecture and weights\n",
    "model.save('model/dinosaur_classifier_transfer_learning.h5')\n",
    "\n",
    "# Save the class labels mapping\n",
    "import json\n",
    "with open('model/dinosaur_class_mapping.json', 'w') as f:\n",
    "    json.dump(test_data.class_indices, f)\n",
    "\n",
    "# Save test performance metrics\n",
    "test_metrics = {\n",
    "    'accuracy': float(accuracy_score(y_true, y_pred)),\n",
    "    'precision': float(precision_score(y_true, y_pred, average='macro')),\n",
    "    'recall': float(recall_score(y_true, y_pred, average='macro')),\n",
    "    'f1_score': float(f1_score(y_true, y_pred, average='macro')),\n",
    "    'classes': test_data.class_indices\n",
    "}\n",
    "\n",
    "with open('model/dinosaur_model_performance.json', 'w') as f:\n",
    "    json.dump(test_metrics, f, indent=2)\n",
    "\n",
    "print(\"Model, class mapping, and performance metrics saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
